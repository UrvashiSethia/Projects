{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e5122c",
   "metadata": {},
   "source": [
    "# Breast Cancer Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117863c",
   "metadata": {},
   "source": [
    "**Building the breast cancer image dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4074e",
   "metadata": {},
   "source": [
    "Our breast cancer image dataset consists of 198,783 images, each of which is 50Ã—50 pixels.\n",
    "\n",
    "If we were to try to load this entire dataset in memory at once we would need a little over 5.8GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9185096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad1ed81d",
   "metadata": {},
   "source": [
    "On Kaggle it is stated that the data set containes 1.5 GB of data, however the set needs more than 4 GB space on dics together with metadata. Images are stored in numerious directories named with a number preresenting the ID of a patient. Such a large data set can not fit into computer memory and during training we have to use a data generator.\n",
    "\n",
    "Data generator expects a path to directory where data is saved in subdirecotries named as the classes. Therefore, we must fistly create tran, validation and test subdirectories where data will be sotred in two directories (since we have binary classification problem).\n",
    "\n",
    "This is a code that will create new directory where all the files will be copied in traning (72% of total data), validation (8% of data) and testing (20% of data) directories. Each directory will contain subdirectories named \"0\" for negative examples and \"1\" for positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc96fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import random, shutil, os\n",
    "\n",
    "random.seed(7)\n",
    "TRAIN_AND_VAL_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f7826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd \"C:\\Users\\HP\\Projects\\Breast Cancer\"   Change directory\n",
    "os.chdir('C:\\\\Users\\\\HP\\\\Projects\\\\Breast Cancer')\n",
    "INPUT_PATH = \"C:\\\\Users\\\\HP\\\\Projects\\\\Breast Cancer\"\n",
    "BASE_PATH = \"Breast_Cancer_Data\\\\arranged\"\n",
    "\n",
    "# ---- Create 3 names for subdirectories containing 3 Sets of data \n",
    "TRAIN_PATH = os.path.join(BASE_PATH + \"\\\\training\")\n",
    "VAL_PATH = os.path.join(BASE_PATH + \"\\\\validation\")\n",
    "TEST_PATH = os.path.join(BASE_PATH + \"\\\\testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b5e66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Get a list of paths for all images in original data using imutils function paths \n",
    "originalPaths = list(paths.list_images(INPUT_PATH))\n",
    "# --- Randomly shuffle all paths in the list\n",
    "random.shuffle(originalPaths)\n",
    "\n",
    "# --- Take first 80% of the paths in trainPaths (TotalTrain)\n",
    "N = int(len(originalPaths)*TRAIN_AND_VAL_SPLIT)\n",
    "trainPaths = originalPaths[:N]\n",
    "# ---- Take last 20% of paths in testPaths\n",
    "testPaths = originalPaths[N:]\n",
    "\n",
    "# --- Take 10% of trainPaths for validation\n",
    "N = int(len(trainPaths)*VAL_SPLIT)\n",
    "valPaths = trainPaths[:N]\n",
    "# --- Take 90% of trainPaths (total) for training data (True training set)\n",
    "trainPaths = trainPaths[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d7d542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222019.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(originalPaths)*TRAIN_AND_VAL_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bead05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19981"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(trainPaths)*VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22cba472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44403.840000000004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(originalPaths)*TRAIN_AND_VAL_SPLIT)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d66844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Crate a list with name, paths to files and path to just base directories\n",
    "datasets=[(\"training\", trainPaths, TRAIN_PATH),\n",
    "          (\"validation\", valPaths, VAL_PATH),\n",
    "          (\"testing\", testPaths, TEST_PATH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c25fb072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set\n",
      "Building directory Breast_Cancer_Data\\arranged\\training\n",
      "Building directory Breast_Cancer_Data\\arranged\\training\\0\n",
      "Building directory Breast_Cancer_Data\\arranged\\training\\1\n",
      "Building validation set\n",
      "Building directory Breast_Cancer_Data\\arranged\\validation\n",
      "Building directory Breast_Cancer_Data\\arranged\\validation\\1\n",
      "Building directory Breast_Cancer_Data\\arranged\\validation\\0\n",
      "Building testing set\n",
      "Building directory Breast_Cancer_Data\\arranged\\testing\n",
      "Building directory Breast_Cancer_Data\\arranged\\testing\\1\n",
      "Building directory Breast_Cancer_Data\\arranged\\testing\\0\n"
     ]
    }
   ],
   "source": [
    "# --- Iterate over all train/valid/test-ing file paths in dataset\n",
    "for (setType, originalPaths, BasePaths) in datasets:\n",
    "        print('Building', setType, 'set')\n",
    "        #If base directory doesn't ecxist- create it\n",
    "        if not os.path.exists(BasePaths):\n",
    "                print('Building directory', BasePaths)\n",
    "                os.makedirs(BasePaths)\n",
    "        \n",
    "        # --- Iterate over all paths in a given setType (train/valid/test-ing)        \n",
    "        for path in originalPaths:\n",
    "            \n",
    "                # --- Get file name using split on path.sep (\\\\)\n",
    "                file = path.split(os.path.sep)[-1]\n",
    "                # --- Position -5 is 0 or 1 because \".png\" are last 4 positions)\n",
    "                label = file[-5]\n",
    "                # --- Create name base directory + \"0\" or \"1\"\n",
    "                labelPath = os.path.join(BasePaths + \"\\\\\" + label)\n",
    "                # --- If this directory doesn't exist - create it\n",
    "                if not os.path.exists(labelPath):\n",
    "                        print('Building directory', labelPath)\n",
    "                        os.makedirs(labelPath)\n",
    "                        \n",
    "                # --- Create path for each file        \n",
    "                newPath=os.path.join(labelPath + \"\\\\\" + file)\n",
    "                # --- Copy file in each old path to newPath  \n",
    "                shutil.copyfile(path, newPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef439f7",
   "metadata": {},
   "source": [
    "Once this is done we can check if we have equal distribution of negative and positive examples over the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ea2e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 2.526 ratio of negative to positive\n",
      "Validation set has 2.497 ratio of negative to positive\n",
      "Testing set has 2.52 ratio of negative to positive\n"
     ]
    }
   ],
   "source": [
    "# --- Count the number of files in each directory                \n",
    "Train_files_0 = len(list(paths.list_images(os.path.join(TRAIN_PATH + \"\\\\0\"))))            \n",
    "Train_files_1 = len(list(paths.list_images(os.path.join(TRAIN_PATH + \"\\\\1\"))))            \n",
    "\n",
    "Val_files_0 = len(list(paths.list_images(os.path.join(VAL_PATH + \"\\\\0\"))))            \n",
    "Val_files_1 = len(list(paths.list_images(os.path.join(VAL_PATH + \"\\\\1\"))))    \n",
    "\n",
    "Test_files_0 = len(list(paths.list_images(os.path.join(TEST_PATH + \"\\\\0\"))))            \n",
    "Test_files_1 = len(list(paths.list_images(os.path.join(TEST_PATH + \"\\\\1\"))))  \n",
    "\n",
    "\n",
    "from numpy import around\n",
    "\n",
    "print('Training set has', around(Train_files_0/Train_files_1, 3), 'ratio of negative to positive')\n",
    "print('Validation set has', around(Val_files_0/Val_files_1, 3), 'ratio of negative to positive')\n",
    "print('Testing set has', around(Test_files_0/Test_files_1,3), 'ratio of negative to positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad71587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f3b3d9",
   "metadata": {},
   "source": [
    " **Train and validate CNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9038969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Conv2D, BatchNormalization, Dense, Dropout, MaxPooling2D, Activation\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "# -- Define number of Epochs, the Batch Size, and global randon seed\n",
    "NUM_EPOCHS = 8\n",
    "BS = 100  \n",
    "tf.random.set_seed(0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27cdfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cancer_clasifier(input_shapes):\n",
    "    \n",
    "    X_input = Input(input_shapes)\n",
    "    \n",
    "    XX = Conv2D(8, kernel_size = (2,2), strides=(1, 1), padding = 'same', \n",
    "                kernel_initializer = GlorotNormal())(X_input)       \n",
    "    XX = BatchNormalization(axis = -1)(XX)\n",
    "    XX = Activation('relu')(XX)\n",
    "    XX = MaxPooling2D(2,2)(XX)\n",
    " \n",
    "    XX = Conv2D(16, kernel_size = (4,4), strides=(1, 1), padding = 'same')(XX)\n",
    "    XX = BatchNormalization(axis = -1)(XX)\n",
    "    XX = Activation('relu')(XX)\n",
    "    XX = MaxPooling2D(2,2)(XX)\n",
    "    \n",
    "    # --- Output Layer\n",
    "    XX = Flatten()(XX)\n",
    "    \n",
    "    XX = Dense(1, activation='sigmoid')(XX)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = XX, name='Cancer_clasifier')\n",
    "              \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3423c72",
   "metadata": {},
   "source": [
    "**Data generator**\n",
    "\n",
    "Define the path to the data set. Be sure that you had run 'arrange_dataset' file before to create testing, validating and training subsets with \"0\" and \"1\" as subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63af8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\Projects\\\\Breast Cancer'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path_to_traning = r\"C:\\Users\\HP\\Projects\\Breast Cancer\\Breast_Cancer_Data\\arranged\\training\"\n",
    "Path_to_validation = r\"C:\\Users\\HP\\Projects\\Breast Cancer\\Breast_Cancer_Data\\arranged\\validation\"\n",
    "\n",
    "print('Current working directory is')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfcc5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199818 images belonging to 2 classes.\n",
      "Found 22201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_shape = (50,50,3)\n",
    "train_augmentation = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.03,\n",
    "        horizontal_flip = True)\n",
    "val_augmentation = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_augmentation.flow_from_directory(\n",
    "        Path_to_traning,\n",
    "        target_size = image_shape[:2],\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size = BS,\n",
    "        class_mode = 'binary',\n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = val_augmentation.flow_from_directory(\n",
    "        Path_to_validation,\n",
    "        target_size = image_shape[:2],\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size = BS,\n",
    "        class_mode = 'binary',\n",
    "        shuffle=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ecbe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- Check if the right classes are recognized by the DirectoryIterator \n",
    "train_generator.class_indices.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e627d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22201, 50, 50, 3)\n",
      "(22201,)\n"
     ]
    }
   ],
   "source": [
    "x=np.concatenate([validation_generator.next()[0] for i in range(validation_generator.__len__())])\n",
    "y=np.concatenate([validation_generator.next()[1] for i in range(validation_generator.__len__())])\n",
    "print(x.shape)\n",
    "print(y.shape)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e47c86a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical(\n",
    "    y, num_classes=2, dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa648ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464ef43",
   "metadata": {},
   "source": [
    "**Train the model**\n",
    "\n",
    "In each Epoch validation accuracy is checked and if it has imporved - model weights are saved in hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95af9655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Cancer_clasifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50, 50, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 50, 50, 8)         104       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 50, 50, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50, 50, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 16)        2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 25, 25, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2305      \n",
      "=================================================================\n",
      "Total params: 4,569\n",
      "Trainable params: 4,521\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "1999/1999 [==============================] - 336s 168ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71407, saving model to model.01-0.71.h5\n",
      "Epoch 2/8\n",
      "1999/1999 [==============================] - 324s 162ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.71407\n",
      "Epoch 3/8\n",
      "1999/1999 [==============================] - 322s 161ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71407\n",
      "Epoch 4/8\n",
      "1999/1999 [==============================] - 318s 159ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.71407\n",
      "Epoch 5/8\n",
      "1999/1999 [==============================] - 328s 164ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.71407\n",
      "Epoch 6/8\n",
      "1999/1999 [==============================] - 329s 165ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.71407\n",
      "Epoch 7/8\n",
      "1999/1999 [==============================] - 315s 157ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.71407\n",
      "Epoch 8/8\n",
      "1999/1999 [==============================] - 313s 157ms/step - loss: 0.0000e+00 - accuracy: 0.7164 - val_loss: 0.0000e+00 - val_accuracy: 0.7141\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.71407\n"
     ]
    }
   ],
   "source": [
    "# -- Create the model\n",
    "my_cancer_model = Cancer_clasifier(image_shape)\n",
    "# -- Print model summary\n",
    "my_cancer_model.summary()\n",
    "\n",
    "    # -- Define the optimizer\n",
    "opt = Adam(learning_rate=0.0001) \n",
    "# -- Compile the model         \n",
    "my_cancer_model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# create the checkpoint for the model with best accuracy on validation set\n",
    "checkpoint_filepath = 'model.{epoch:02d}-{val_accuracy:.2f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath = checkpoint_filepath, monitor='val_accuracy',verbose=1, \n",
    "                             save_best_only = True, save_weights_only = False, save_freq = 'epoch')\n",
    "               \n",
    "# -- Train the model                         \n",
    "history = my_cancer_model.fit(train_generator, validation_data = validation_generator, epochs = NUM_EPOCHS, \n",
    "                              callbacks=[checkpoint], \n",
    "                              steps_per_epoch = len(train_generator),\n",
    "                              validation_steps = len(validation_generator))                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11750d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9692524c",
   "metadata": {},
   "source": [
    "**Saving the model in json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ab7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = my_cancer_model.to_json()\n",
    "with open(\"Cancer_clasifier_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "my_cancer_model.save_weights(\"Cancer_clasifier_LastWeights.h5\")\n",
    "\n",
    "# Save model history with json \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "# save to json:  \n",
    "hist_json_file = 'Model_History.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6544c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69dbe69e",
   "metadata": {},
   "source": [
    "Validate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b84fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell if you want to load saved model and weights\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "json_file = open('Cancer_clasifier_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "my_cancer_model = model_from_json(loaded_model_json)\n",
    "# my_cancer_model.load_weights('model.05-0.86.h5')\n",
    "image_shape = (50,50,3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "461c6666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the classes on the test set and calculating the confusion matrix ..\n",
      "Found 55505 images belonging to 2 classes.\n",
      "556/556 [==============================] - 31s 55ms/step\n",
      "Confussion matrix is \n",
      " [[38926   810]\n",
      " [15549   220]]\n",
      "Accuracy: 0.7052697955139177\n",
      "Sensitivity 0.013951423679370918\n",
      "Specificity 0.9796154620495269\n"
     ]
    }
   ],
   "source": [
    "print('Predicting the classes on the test set and calculating the confusion matrix ..')\n",
    "Path_to_test = r\"C:\\Users\\HP\\Projects\\Breast Cancer\\Breast_Cancer_Data\\arranged\\testing\"\n",
    "\n",
    "test_augmentation = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_augmentation.flow_from_directory(\n",
    "        Path_to_test,\n",
    "        target_size = image_shape[:2],\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size = BS,   \n",
    "        class_mode = 'binary',\n",
    "        shuffle=False)\n",
    "\n",
    "# ---- Predictions from the model on test set\n",
    "predicted_indices = my_cancer_model.predict(test_generator, verbose = 1, steps = len(test_generator))\n",
    "predicted_indices[predicted_indices < 0.5] = 0\n",
    "predicted_indices[predicted_indices >= 0.5] = 1  \n",
    "\n",
    "# --- Create Confusion matrix \n",
    "cm = confusion_matrix(test_generator.classes, predicted_indices)\n",
    "total = sum(sum(cm))\n",
    "# --- Calculate and print acc, spec & sens\n",
    "accuracy = (cm[0,0]+cm[1,1])/total\n",
    "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "sensitivity = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "\n",
    "\n",
    "print('Confussion matrix is \\n', cm)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Sensitivity', sensitivity)\n",
    "print('Specificity', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbad5678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.026192035240192868\n",
      "BAC 0.4967834428644489\n"
     ]
    }
   ],
   "source": [
    "Rc = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "Pr = cm[1,1]/(cm[1,1] + cm[0,1])\n",
    "F1 = 2*Rc*Pr/(Rc+Pr)  \n",
    "print('F1 score', F1)      \n",
    "print('BAC', (specificity + sensitivity)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029cb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8181914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
